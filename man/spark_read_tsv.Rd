% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/data_interface.R
\name{spark_read_tsv}
\alias{spark_read_tsv}
\title{Read a TSV file into a Spark DataFrame}
\usage{
spark_read_tsv(
  sc,
  path,
  name = NULL,
  header = FALSE,
  columns = NULL,
  repartition = 0,
  overwrite = FALSE,
  ...
)
}
\arguments{
\item{sc}{A \code{spark_connection}.}

\item{path}{Path to the input file (\samp{"hdfs://"}, \samp{"s3a://"} and \samp{"file://"} protocols are supported).}

\item{name}{Name to assign to the resulting Spark dataframe.}

\item{header}{Whether the first row of data be used as a header (default: FALSE)}

\item{columns}{A vector of column names or a named vector of column types.}

\item{repartition}{Number of partitions to have in the resulting Spark dataframe. Use 0 (the default) to avoid partitioning.}

\item{overwrite}{Whether to overwrite any existing Spark dataframe with the given name.}

\item{...}{Additional arguments to sparklyr::spark_read_csv()}
}
\description{
Read a tabular data file into a Spark DataFrame.
}
